# Web Application - Application Mapping

The first step in the process of attacking an application is gathering and
examining some key information about it to gain a better understanding of what
you are up against.

The mapping exercise begins by **enumerating the applicationâ€™s content and
functionality** in order to understand what the application does and
how it behaves.

--------------------------------------------------------------------------------

### Manual browsing + passive spidering

Browse the entire application in the normal way, visiting every link and URL,
submitting every form, and proceeding through all multistep functions to
completion.

If the application uses authentication, and you have or can create a login
account, use this to access the authenticated functionality.

###### Comments Review
Review comments in HTML source code
```
<!--
//
/*
```

###### Robots.txt
Check if the robots.txt ($ROOT/robots.txt) or sitemap.xml ($ROOT/sitemap.xml)
files are presents.

###### JS & Cookies
Browse with JavaScript enabled and disabled, and with cookies enabled and
disabled.

###### User-Agent
Change the User-Agent header to identify difference in comportment (for
example, the application may have a mobile version).
Firefox addon that allows for quickly changing the browser's user agent string:
`User Agent Switcher`  

*Agents*  
```
# Browser
Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0
# Mobile
Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1
```


###### Debug parameters
Choose one or more application pages or functions where hidden debug parameters
may be implemented.
Use cluster bomb attack in Burp Intruder and a list of the following common
debug parameter names
```
debug
test
hide
hidden
source
```
Test with common values (such as true, yes, on, and 1).
For POST requests, supply the parameter in both the URL query string and the
request body

###### Burp Passive Spidering
Review the site map generated by the passive spidering, and identify any
content or functionality that you have not walked through using your browser.

Browse it and continue this step recursively until no further content or
functionality is identified.

### Search engine dork

Returns every resource within the target site that Google has a reference to.
```
site:www.target.com
```

Returns all the pages containing the expression login referenced by Google.
```
site:www.target.com login
```

Returns all the pages on other websites and applications that contain a link
to the target.
```
link:www.target.com
```

Browse to the last page of search results for a given query, and select
```
Repeat the Search with the Omitted Results Included
```


### Content Management System fingerprinting

Determine the technologies in use:

- Verbose HTTP headers
- Default error pages
- HTML source code comments and variable names
- JavaScript files names

Check for default content associated with the technologies found : automate the
discovery of default files and directories using wordlist of default or common
content for the technologies found
```
# wordlists
Discovery/Web_Content/*
```

### Active spidering & URL bruteforcing

Actively spider the application using all of the already enumerated content as
a starting point.

###### Burp Active Spider
Start the BurpSuite Active Spidering.
Complete authentication forms if possible.

###### Directory bruteforce

Use the application root and any other path from already enumerated deemed fit
as a starting point.

*File extension*  
Determine file extension to use for the bruteforce (no extension +
language extension).

*Wordlists*  
Adapte the word list for the application context.
Example: if all resources in start with a capital letter, the wordlist used in
the bruteforce should be capitalized.
```
/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
```
*Tools*
```
# GUI
DirBuster
BurpSuite Intruder
# CLI
gobuster
wfuzz
dirb
```
